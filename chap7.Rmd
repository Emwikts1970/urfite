<div class = "keyconcept"> 
<h3 class = "right"> Key Concept 7.1 </h3>          
<h3 class = "left"> Testing the hypothesis $\beta_j = \beta_{j,0}$ <br>
                    against the alternative $\beta_j \neq \beta_{j,0}$ </h3>

<p>
1. Compute the standard error of $\hat{\beta_j}$
2. Compute the t-statistic,
$$t = \frac{\hat{\beta}_j - \beta_{j,0}} {SE(\hat{\beta_j})}$$
3. Compute the p-value,
$$p-value = 2 \phi(-|t^{act}|)$$

where $t^{act}$ is the value of the t-statistic actually computed. Reject the hypothesis at the 5\% significance level if the p-value is less than $0.05$ or, equivalently, if $|t^{act}| > 1.96$. The standard error and (typically) the t-statistic and p-value testing $\beta_j = 0$ are computed automativally by statistical software.  
</p>
  
</div>

<div class = "keyconcept"> 
<h3 class = "right"> Key Concept 7.2 </h3>          
<h3 class = "left"> Confidence Intervals for a single coefficient in multipe regression </h3>

<p>
A $95\%$ two-sided confidence interval for coefficient $\beta_j$ is an interval that contains the true value of $\beta_j$ with a $95 \%$ probability; that is, it contains the true value of $\beta_j$ in $95 \%$ of all randomly drawn samples. Equivalently, it is the set of values of $\beta_j$ that cannot be rejected by a $5 \%$ two-sided hypothesis test. When the sample size is large, the $95 \%$ confidence interval for $\beta_j$ is
$$[\hat{\beta_j}- 1.96 SE(\hat{\beta}_j), \hat{\beta_j} + 1.96 SE(\hat{\beta_j})]$$
</p>
</div>

##Application to Test Scores and the Student-Teacher Ratio

Let us take a look at the regression in section 6.3 again.

<div class="fold o">
```{r, echo=5:7, warning=F, message=F}
library(AER)
data(CASchools)
CASchools$tsratio  <- CASchools$students/CASchools$teachers
CASchools$score    <- (CASchools$read + CASchools$math)/2
# Confidence Intervals - Application to Test Scores and the Student-Teacher Ratio
model <- lm(score ~ tsratio + english, data = CASchools)
summary(model)
```
</div>

<div class = "keyconcept"> 
<h3 class = "right"> Key Concept 7.3 </h3>          
<h3 class = "left"> Omitted variable bias in multiple regression</h3>

<p>

Omitted Variable bias is the bias in the OLS estimator that arises when one or more included regressors are correlated with an omitted variable. For omitted variable bias to arise, twho things must be true: 

1. At least one of the included regressors mut be correlated with the omitted variable 
2. The omitted variable must be a determinant of the dependent variable, $Y$.

</p>
  
</div>