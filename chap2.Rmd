This chapter reviews basic concepts of probability theory and how they can be applied in R. 

The most common probability distributions are implemented in base R. That means that You can draw random numbers from these distributions, compute densities, probabilies, quantiles and alike. It is often very convenient to rely on these routines, especially when writing Your own functions.  

## Section 2.1 --- Discrete Random Variables

A basic function to draw random samples from a specified set of elements is the the function `sample`, see `?sample`. We can use it to conduct simple random experiments, for example throwing a dice: this is nothing but randomly selecting a sample of size 1 from a set of numbers $\{1,2,3,4,5,6\}$. Let's role the dice!

```{r, echo = T, eval = T, message = F, warning = F}
sample(c(1,2,3,4,5,6),1)
```

An example of sampling with replacement is rowling a dice three times in a row.  

```{r, echo = T, eval = T, message = F, warning = F}
sample(c(1,2,3,4,5,6),3, replace = T)
```

The set of elements `sample` draws from does not have to consist of numbers only. We might as well simulate coin tossing with outcomes H (head) and T (tail).

```{r, echo = T, eval = T, message = F, warning = F}
sample(c("H","T"),1)
```

#### Bernoulli Trials

The result of a coin toss is a Bernoulli distributed random variable i.e. two distinct outcomes are possible.

Imagine you are about to toss a coin 10 times in a row and wonder how likely it is to end up with a sequence of outcomes like

$$ H \, H \, T \, T \,T \,H \,T \,T \, H \, H $$

$(H$=Head, $T$=Tail$)$

This is a typical example of a Bernoulli experiment as it consists of $n=10$ Bernoulli trials that are independent of each other and we are interested in the likelihood of observing $k=5$ successes $H$ that occur with probability $p=0.5$ (assuming a fair coin) in each trial.

It is a well known result that $k$ follows a binomial distribution 

$$ k \sim B(n,p). $$

The probability of observing $k$ successes in the experiment $B(n,p)$ is hence given by

$$f(k)=P(k)=\begin{pmatrix}n\\ k \end{pmatrix} \cdot p^k \cdot q^{n-k}=\frac{n!}{k!(n-k)!} \cdot p^k \cdot q^{n-k}$$


where $\begin{pmatrix}n\\ k \end{pmatrix}$ is a binomial coefficient. In R, we can solve the problem stated above by means of the function `dbinom` which calculates the density of the binomial distribution for parameters `x`, `size`, and `prob`, see `?binom`.

```{r, echo = T, eval = T, message = F, warning = F}
dbinom(x = 5, size = 10, prob = 0.5)
```

We conclude that the probability of observing $H$ $k=5$ times when tossing the coin $n=10$ times is about $24.6\%$.

Now assume You are interested in $P(4 \leq k \leq 7)$ i.e. the probability of observing 4, 5, 6 or 7 successes for $B(n,p)$. This is easily computed by providing a vector as the `x` argument in `dbinom` and summing up using `sum`.

```{r, echo = T, eval = T, message = F, warning = F}
sum(dbinom(x = c(4:7), size = 10, prob = 0.5))
```

The Probability distribution of a discrete random variable is nothing but a list of all possible outcomes that can occur and their respective probabilities. In our coin tossing example, we face 11 possible outcomes for $k$

```{r, echo = T, eval = T, message = F, warning = F}
k <- 0:10
```

To visualize the probability density function of $k$ we may therefore simply call

<div class="unfolded">
```{r, echo = T, eval = T, message = F, warning = F}
density <- dbinom(x = 0:10, size = 10, prob = 0.5)
k <- 0:10
plot(k,density)
```
</div>

In a similar fashion we may plot the cummulative distribution function of $k$ by executing

```{r, echo = T, eval = T, message = F, warning = F}
prob <- cumsum(dbinom(x = 0:10, size = 10, prob = 0.5))
k <- 0:10
plot(k,prob)
```

